{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Theoretical Questions :**"
      ],
      "metadata": {
        "id": "KiGoRmfUZ7Yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "- Logistic Regression is a supervised learning algorithm used for classification problems, where the dependent variable (output) is categorical—typically binary (e.g., Yes/No, 0/1, True/False). It predicts the probability that an observation belongs to a particular class. The model uses the logistic (sigmoid) function to map predicted values to a range between 0 and 1, making it suitable for probability estimation. The general form of the logistic function is:\n",
        "\n",
        "$$\n",
        "P(Y = 1) = \\frac{1}{1 + e^{-(b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n)}}\n",
        "$$\n",
        "Linear Regression, on the other hand, is used for regression problems, where the dependent variable is continuous (e.g., predicting sales, temperature, or prices). It models the relationship between independent variables and the dependent variable by fitting a straight line through the data, represented as:\n",
        "\n",
        "$$\n",
        "Y = b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n\n",
        "$$\n",
        "\n",
        "\n",
        "| Aspect                | Linear Regression                            | Logistic Regression                                     |\n",
        "| --------------------- | -------------------------------------------- | ------------------------------------------------------- |\n",
        "| **Purpose**           | Predicts a continuous outcome                | Predicts a categorical outcome (usually binary)         |\n",
        "| **Output Range**      | Any real number                              | Between 0 and 1 (as probability)                        |\n",
        "| **Function Used**     | Linear function                              | Sigmoid (logistic) function                             |\n",
        "| **Error Measurement** | Measured using Mean Squared Error (MSE)      | Measured using Log Loss or Cross-Entropy                |\n",
        "| **Linearity**         | Models linear relationship between variables | Models the log-odds (logit) of the probability linearly |\n",
        "| **Use Case Example**  | Predicting house prices                      | Predicting if an email is spam or not                   |\n"
      ],
      "metadata": {
        "id": "ejaOfq24aKWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Explain the role of the Sigmoid function in Logistic Regression.\n",
        "- The Sigmoid function, also known as the logistic function, plays a crucial role in Logistic Regression by converting the output of a linear equation into a probability value between 0 and 1.\n",
        "\n",
        "The Sigmoid function is defined as:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "where,\n",
        "\n",
        "$$\n",
        "z = b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n\n",
        "$$\n",
        "\n",
        "Key Roles of the Sigmoid Function:\n",
        "\n",
        "Probability Mapping:\n",
        "\n",
        "The linear combination\n",
        " $$\n",
        "z = b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n\n",
        "$$\n",
        "\n",
        "\n",
        " can take any real value from −∞ to +∞.\n",
        "The Sigmoid function maps this range to (0, 1), making it interpretable as a probability that the output belongs to a particular class (e.g.,\n",
        "P(Y=1)).\n",
        "\n",
        "Decision Boundary:\n",
        "\n",
        "By setting a threshold (commonly 0.5), the Sigmoid output can be used to classify data:\n",
        "\n",
        "If\n",
        "\n",
        "σ(z)≥0.5, predict class 1\n",
        "\n",
        "If\n",
        "\n",
        "σ(z)<0.5, predict class 0\n",
        "\n",
        "Smooth and Differentiable:\n",
        "\n",
        "The Sigmoid function is smooth and differentiable, which is essential for optimization using gradient descent during model training.\n",
        "\n",
        "Non-linearity Introduction:\n",
        "\n",
        "Although Logistic Regression is a linear model in parameters, the Sigmoid function introduces non-linearity in the output, allowing it to model binary outcomes effectively."
      ],
      "metadata": {
        "id": "WVfLJuLla2Sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is Regularization in Logistic Regression and why is it needed?\n",
        "-  **Regularization** is a technique used in **Logistic Regression** to **prevent overfitting** by adding a **penalty term** to the cost (loss) function.  \n",
        "Overfitting happens when the model learns the noise and details of the training data, reducing its performance on unseen data.  \n",
        "Regularization discourages the model from assigning excessively large weights to the features, thereby improving **generalization**.\n",
        "\n",
        "\n",
        "\n",
        "### **Mathematical Representation**\n",
        "\n",
        "The regularized cost function in Logistic Regression is:\n",
        "\n",
        "$$\n",
        "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\Big[ y_i \\log(h_\\theta(x_i)) + (1 - y_i) \\log(1 - h_\\theta(x_i)) \\Big] + \\lambda R(\\theta)\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- \\( h_\\theta(x_i) \\) = predicted probability using the sigmoid function  \n",
        "- \\( m \\) = number of training samples  \n",
        "- \\( \\lambda \\) = regularization parameter controlling penalty strength  \n",
        "- \\( R(\\theta) \\) = regularization term (depends on type)\n",
        "\n",
        "\n",
        "\n",
        "### **Types of Regularization**\n",
        "\n",
        "#### **i. L1 Regularization (Lasso)**\n",
        "Adds the absolute value of coefficients to the cost function:\n",
        "\n",
        "$$\n",
        "R(\\theta) = \\sum_{j=1}^{n} |\\theta_j|\n",
        "$$\n",
        "\n",
        "It can shrink some coefficients to **zero**, effectively performing **feature selection**.\n",
        "\n",
        "\n",
        "\n",
        "#### **ii. L2 Regularization (Ridge)**\n",
        "Adds the squared value of coefficients to the cost function:\n",
        "\n",
        "$$\n",
        "R(\\theta) = \\sum_{j=1}^{n} \\theta_j^2\n",
        "$$\n",
        "\n",
        "It **reduces large coefficients** smoothly without completely eliminating them.\n",
        "\n",
        "\n",
        "### **Why Regularization is Needed**\n",
        "\n",
        "- **Prevents overfitting:** Keeps the model from fitting the noise in data.  \n",
        "- **Improves generalization:** Enhances performance on unseen data.  \n",
        "- **Controls coefficient size:** Avoids excessively large parameter values.  \n",
        "- **Stabilizes optimization:** Ensures smoother and more reliable training.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f9WCRGYGfHRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. : What are some common evaluation metrics for classification models, and\n",
        "why are they important?\n",
        "-  **Evaluation metrics** are used to measure the **performance** of classification models.  \n",
        "They help determine how well the model is making predictions and whether it is suitable for real-world deployment.  \n",
        "Different metrics capture different aspects of model performance such as accuracy, precision, recall, and overall balance between them.\n",
        "\n",
        "\n",
        "\n",
        "### **1. Accuracy**\n",
        "\n",
        "Accuracy measures the proportion of correctly predicted observations to the total observations.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- \\( TP \\): True Positives  \n",
        "- \\( TN \\): True Negatives  \n",
        "- \\( FP \\): False Positives  \n",
        "- \\( FN \\): False Negatives  \n",
        "\n",
        "Accuracy works well when the dataset is **balanced**, but it can be **misleading** for **imbalanced datasets**.\n",
        "\n",
        "\n",
        "\n",
        "### **2. Precision**\n",
        "\n",
        "Precision measures how many of the predicted positive cases are actually positive.\n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "It is useful when the **cost of false positives** is high (e.g., spam detection).\n",
        "\n",
        "\n",
        "\n",
        "### **3. Recall (Sensitivity or True Positive Rate)**\n",
        "\n",
        "Recall measures how many of the actual positive cases were correctly identified.\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "It is important when **missing positive cases** is costly (e.g., medical diagnosis).\n",
        "\n",
        "\n",
        "\n",
        "### **4. F1-Score**\n",
        "\n",
        "F1-Score is the **harmonic mean** of Precision and Recall.  \n",
        "It balances the trade-off between them.\n",
        "\n",
        "$$\n",
        "\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "It is especially useful for **imbalanced datasets**.\n",
        "\n",
        "\n",
        "\n",
        "### **5. ROC Curve and AUC (Area Under the Curve)**\n",
        "\n",
        "- The **ROC curve** plots the **True Positive Rate (TPR)** against the **False Positive Rate (FPR)** at various threshold settings.  \n",
        "- The **AUC** represents the **area under this curve** and indicates how well the model distinguishes between classes.\n",
        "\n",
        "$$\n",
        "\\text{TPR} = \\frac{TP}{TP + FN}, \\quad \\text{FPR} = \\frac{FP}{FP + TN}\n",
        "$$\n",
        "\n",
        "A higher AUC value (closer to 1) indicates a better-performing model.\n",
        "\n",
        "\n",
        "\n",
        "### **Importance of Evaluation Metrics**\n",
        "\n",
        "- They provide **quantitative measures** of model performance.  \n",
        "- Help in **model comparison** and **hyperparameter tuning**.  \n",
        "- Identify **strengths and weaknesses** (e.g., sensitivity vs. specificity).  \n",
        "- Ensure the model is **reliable and fair**, especially in critical applications.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IR6kdkffgtSM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-tKPofkRSZh"
      },
      "outputs": [],
      "source": [
        "# 5. Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "# splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb80decb"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "breast_cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
        "df['target'] = breast_cancer.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ecef6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74d3b1e-2b6a-4dc3-c576-253f903622a8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (455, 30)\n",
            "Testing set shape: (114, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8665896b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "35850245-ccf7-44fb-e893-a246295ddd12"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU2fKlghijML",
        "outputId": "58cdc115-4801-493d-b40f-78c3411195dc"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdbd3d24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d19902-b1e9-4c94-e083-02c8594a3e74"
      },
      "source": [
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #6. Write a Python program to train a Logistic Regression model using L2\n",
        "# regularization (Ridge) and print the model coefficients and accuracy.\n",
        "\n",
        "# Step 1: Import Libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 2: Load Dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 3: Split into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Step 4: Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 5: Train Logistic Regression with L2 Regularization (Ridge)\n",
        "# multi_class='ovr' for One-vs-Rest strategy\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', multi_class='ovr', random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 6: Print Model Coefficients\n",
        "print(\"Model Coefficients:\\n\", model.coef_)\n",
        "print(\"Model Intercept:\\n\", model.intercept_)\n",
        "\n",
        "# Step 7: Evaluate Model Accuracy\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy on Test Set:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIBVGB-xBiaX",
        "outputId": "ba42ea11-5550-48e2-b4f4-e44954044cd6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients:\n",
            " [[-0.82629339  1.29687882 -1.60852314 -1.43624942]\n",
            " [ 0.06394239 -1.24520478  0.84925141 -0.90288382]\n",
            " [ 0.10388483 -0.01359343  1.58911662  2.54884662]]\n",
            "Model Intercept:\n",
            " [-1.55171933 -0.89578062 -2.38035044]\n",
            "Accuracy on Test Set: 0.8333333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Write a Python program to train a Logistic Regression model for multiclass\n",
        "# classification using multi_class='ovr' and print the classification report.\n",
        "\n",
        "# Step 1: Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Optional: Convert to DataFrame for clarity\n",
        "df = pd.DataFrame(X, columns=iris.feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "# Step 3: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y)\n",
        "\n",
        "# Step 4: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 5: Train Logistic Regression with one-vs-rest (OvR)\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Step 7: Print classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-OYo689BS-c",
        "outputId": "21f9392a-fd2e-4f06-9e93-f296c6959e88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       0.86      0.60      0.71        10\n",
            "   virginica       0.69      0.90      0.78        10\n",
            "\n",
            "    accuracy                           0.83        30\n",
            "   macro avg       0.85      0.83      0.83        30\n",
            "weighted avg       0.85      0.83      0.83        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "# hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "# accuracy.\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Create Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000, solver='liblinear')\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,             # 5-fold cross-validation\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and corresponding score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy: {:.2f}\".format(grid_search.best_score_))\n",
        "\n",
        "# Evaluate on test data\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Test Accuracy: {:.2f}\".format(accuracy_score(y_test, y_pred)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6e2Yz3S9dDp",
        "outputId": "1885e5aa-339b-40c1-807c-fc4bb44b77d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.1, 'penalty': 'l2'}\n",
            "Best Cross-Validation Accuracy: 0.92\n",
            "Test Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. : Write a Python program to standardize the features before training Logistic\n",
        "# Regression and compare the model's accuracy with and without scaling.\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "model_no_scaling = LogisticRegression(max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "acc_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "\n",
        "print(\"Accuracy WITHOUT Scaling: {:.4f}\".format(acc_no_scaling))\n",
        "print(\"Accuracy WITH Scaling:    {:.4f}\".format(acc_scaled))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExNteltg93bO",
        "outputId": "c600c6df-f1a3-4a5a-af89-8e7a68587834"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy WITHOUT Scaling: 0.9708\n",
            "Accuracy WITH Scaling:    0.9825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "\n",
        "-   The goal is to predict whether a customer will respond to a marketing campaign using Logistic Regression. The dataset is highly imbalanced, with only 5% of customers responding, which makes it challenging for standard predictive models.\n",
        "\n",
        "1. Data Handling and Preprocessing\n",
        "\n",
        "Data Cleaning: Handle missing values, remove duplicates, and check for outliers.\n",
        "\n",
        "Feature Engineering: Create variables such as customer tenure, purchase frequency, average spending, and recency of last purchase.\n",
        "\n",
        "Encoding Categorical Variables: Convert categorical features like gender or region using one-hot or label encoding.\n",
        "\n",
        "2. Feature Scaling\n",
        "\n",
        "Logistic Regression is sensitive to feature magnitudes. Numerical features should be standardized (subtract the mean and divide by the standard deviation) so that all features contribute equally to the model and training converges effectively.\n",
        "\n",
        "3. Handling Class Imbalance\n",
        "\n",
        "Resampling Techniques: Oversample the minority class using SMOTE or undersample the majority class to balance the dataset.\n",
        "\n",
        "Class Weights: Assign higher weight to the minority class in the Logistic Regression model using class_weight='balanced' so the model focuses more on responders.\n",
        "\n",
        "4. Model Building\n",
        "\n",
        "Split the dataset into training (80%) and testing (20%) sets.\n",
        "\n",
        "Train a Logistic Regression model with regularization (L1 or L2).\n",
        "\n",
        "Use Grid Search or Randomized Search for hyperparameter tuning, such as adjusting regularization strength (C) and penalty type.\n",
        "\n",
        "5. Model Evaluation\n",
        "\n",
        "For imbalanced datasets, accuracy is not sufficient. Use:\n",
        "\n",
        "Precision: Measures how many predicted responders actually responded.\n",
        "\n",
        "Recall: Measures how many actual responders were correctly identified.\n",
        "\n",
        "F1-Score: Balances precision and recall.\n",
        "\n",
        "ROC-AUC: Evaluates the model’s ability to distinguish responders from non-responders.\n",
        "\n",
        "Confusion Matrix: Visualizes true positives, false positives, true negatives, and false negatives.\n",
        "\n",
        "6. Business Application\n",
        "\n",
        "The model predicts the probability of each customer responding. Customers with high predicted probabilities can be targeted for campaigns, optimizing marketing spend and maximizing ROI. This approach ensures resources are focused on the most promising customers, improving campaign effectiveness.\n",
        "\n",
        "7. Summary\n",
        "\n",
        "Clean and preprocess the data.\n",
        "\n",
        "Scale numerical features.\n",
        "\n",
        "Handle class imbalance through resampling or class weights.\n",
        "\n",
        "Train and tune a Logistic Regression model.\n",
        "\n",
        "Evaluate performance using precision, recall, F1-score, and ROC-AUC.\n",
        "\n",
        "Apply predictions to guide targeted marketing campaigns.\n"
      ],
      "metadata": {
        "id": "GwZlAnFO-gPw"
      }
    }
  ]
}